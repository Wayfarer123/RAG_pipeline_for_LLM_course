{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as numpy\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "with open(\"tokens.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    private_keys = json.load(f)\n",
    "\n",
    "\n",
    "folder_id = private_keys['yandex_cloud_dir_identifier']\n",
    "api_key = private_keys['yandex_cloud_key']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в качестве маленького датасета возьмем кусок старого конспекта базового курса по машинке\n",
    "titles = [\n",
    "    \"Machine Learning problem statement. Regression, Classification, examples.\",\n",
    "    \"How to measure quality in classification: accuracy, balanced accuracy, precision, recall, f1-score, ROC-AUC, multiclass extensions\",\n",
    "    \"How to measure quality in regression: MSE, MAE, R2.\",\n",
    "    \"Maximum likelihood estimation, how is it related to regression and classification\",\n",
    "    \"Naive bayesian classifier, how does it work\",\n",
    "    \"K-nearest neighbours classifier, how does it work\",\n",
    "    \"Linear regression. Problem statement for the MSE loss function case. Analytical solution. Gauss-Markov theorem. Gradient approach in linear regression.\",\n",
    "    \"Regularization in linear models: L1 и L2, their properties. Probabilistic interpretation.\",\n",
    "    \"Logistic regression. Equivalence of MLE approach and logistic loss minimization.\",\n",
    "    \"Multiclass classification. One-vs-one, one-vs-all, their properties.\",\n",
    "    \"Support vector machine. Optimization problem for SVM. Kernel trick. Kernel properties.\",\n",
    "    \"Principal component analysis. Relations to SVD. Eckart-Young theorem. How to apply PCA in practice.\",\n",
    "    \"Train, validation and test stages of model development. Overfitting problem, ways to detect it.\",\n",
    "    \"Validation strategies. Cross validation. Data leaks.\",\n",
    "    \"Bias-variance tradeoff.\",\n",
    "    \"Decision tree construction procedure.\",\n",
    "    \"Information criteria. Entropy criteria, Giny impurity.\",\n",
    "    \"Ensembling methods. Bootstrap. Bagging.\",\n",
    "    \"Random Forest, Random subspace method.\",\n",
    "    \"Boosting and gradient boosting. Main idea, gradient derivation.\",\n",
    "    \"Matrix calculus and matrix derivatives. How to get the derivative of matrix/dot product\",\n",
    "    \"Backpropagation, chain rule.\"\n",
    "]\n",
    "\n",
    "texts = []\n",
    "\n",
    "texts_dir = \"D:/Desktop/9сем/LLM/RAG_pipeline_for_LLM_course/5sem_ml/section/\"\n",
    "\n",
    "for file in sorted(os.listdir(texts_dir), key=lambda x: int(x.split(\".\")[0])):\n",
    "    with open(texts_dir + file, \"r\", encoding=\"utf-8\") as f:\n",
    "        texts.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_with_titles = [{\n",
    "        \"text\": text[:6000],\n",
    "        \"title\": title\n",
    "    } for title, text in zip(titles, texts)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from yandex_chain import YandexEmbeddings\n",
    "\n",
    "embeddings = YandexEmbeddings(\n",
    "    folder_id=folder_id, \n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "vec = embeddings.embed_query(\"Hello, world!\")\n",
    "len(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf db\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "db = Chroma(\n",
    "    embedding_function=embeddings, \n",
    "    persist_directory='./db'\n",
    ")\n",
    "\n",
    "for d in texts_with_titles:\n",
    "    db.add_texts(\n",
    "        [d[\"title\"]], \n",
    "        metadatas=[{\n",
    "            \"title\": d[\"title\"],\n",
    "            \"text\": d[\"text\"]\n",
    "        }]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='03ce01f5-e0ca-4625-b558-3750b3b579ac', metadata={'text': 'Напомним, что аналитическое решение для метода наименьших квадратов выглядит следующим образом:\\n\\n\\\\[\\n\\\\widehat{w} = (X^T X)^{-1} X^T Y\\n\\\\]\\n\\nВидно, что нам приходится искать матрицу, обратную к $X^T X$. Однако, что делать, если эта матрица вырождена (или близка к вырожденной)? \\n\\nСначала подумаем, что означает вырожденность матрицы $X^T X$. Это означает, что в этой матрице (а значит, и в матрице $X$) есть линейно зависимые столбцы (признаки). В таком случае столбец весов не может быть определён однозначно, так как будет фиксирована только сумма весов этих параметров, а сами параметры могут определяться континуальным количеством способов.\\n\\nЕсли же матрица $X^T X$ близка к вырожденной, то решение получается \\\\textit{нестабильным} (то есть при добавлении небольшого шума в данные вектор весов меняется сильно).\\n\\nЧтобы решить эту проблему, нам хочется ограничить свободу выбора этих коэффициентов, наложить дополнительное условие, чтобы решение стало единственным. Давайте потребуем, чтобы норма вектора весов была наименьшей из возможных. Тогда задача оптимизации запишется следующим образом:\\n\\n\\\\[\\n\\\\widehat{w} = \\\\underset{w}{\\\\argmin}\\n\\\\left( \\\\|Y - Xw\\\\|_2^2 + \\\\lambda \\\\|w\\\\|_2^2 \\\\right)\\n\\\\]\\n\\nКоэффициент $\\\\lambda$ -- это гиперпараметр, который отвечает за то, насколько важно для нас, чтобы норма вектора весов была маленькая.\\n\\n\\\\textbf{Важное замечание.}\\nВ слагаемом \\\\(\\\\lambda \\\\|w\\\\|_2^2\\\\) мы записываем $w$ без свободного члена ($w_0$), так как иначе наша модель будет стараться уменьшать в том числе и $w_0$, то есть пытаться провести гиперплоскость через ноль. В общем случае это не следует не из каких предположений, поэтому накладывать ограничение на $w_0$ нельзя.\\n\\nАналитическое решение такой задачи будет выглядеть следующим образом:\\n\\n\\\\[\\n\\\\widehat{w} = \\\\left( X^T X + \\\\lambda I \\\\right)^{-1} X^T Y\\n\\\\]\\n\\nВидно, что теперь обратная матрица существует всегда (так как  к $X^T X$ мы добавляем единичную матрицу).\\n\\nПодход, при котором мы накладываем дополнительные ограничение, называется \\\\textit{регуляризацией}. При этом не обязательно накладывается ограничение на норму вектора весов (см. другие примеры в билете \\\\ref{27}).\\n\\nМожно применять не только $L2$ регуляризацию, но и $L1$.\\n\\n\\\\textbf{L2}\\n\\\\begin{itemize}\\n    \\\\item имеет аналитическое решение\\n    \\\\item дифференцируема\\n\\\\end{itemize}\\n\\n\\\\textbf{L1}\\n\\\\begin{itemize}\\n    \\\\item не дифференцируема\\n    \\\\item \"отбирает\" признаки\\n\\\\end{itemize}', 'title': 'Regularization in linear models: L1 и L2, their properties. Probabilistic interpretation.'}, page_content='Regularization in linear models: L1 и L2, their properties. Probabilistic interpretation.'),\n",
       " Document(id='2c01cb86-555a-40dd-b4e0-968509e0c291', metadata={'text': '\\\\textbf{Постановка задачи}\\n\\n$X \\\\in \\\\R^{n \\\\times p}, Y \\\\in C^n$, где $C$ -- это множество меток классов (конечное). Если метки не упорядочены, то это называется \\\\textit{задачей классификации}.\\n\\nПока что будет заниматься бинарной классификацией и для удобства будем считать, что \\\\(C = \\\\{-1, 1\\\\}\\\\). Обозначим за $c(X)$ функцию, которая возвращает $\\\\widehat{Y}$, то есть предсказание классов нашей модели.\\n\\nДопустим у нас есть матрица признаков и вектор весов, как из этого всего, что уже было в линейной регрессии,\\nсоставить линейную классификацию?\\nНадо делить на классы предсказанный ответ, обрубая по какой-то границе, если у нас два класса.\\n\\n\\\\[\\nc(x) = \\n\\\\begin{cases}\\n1, f(x) \\\\geqslant 0 \\\\\\\\\\n-1, f(x) < 0\\n\\\\end{cases}\\n\\\\]\\n\\nПусть вектор $w$ является нормалью к гиперплоскости в $p$-мерном пространстве фичей (гиперплоскость задаётся уравнением $x^T w = 0$), с одной стороны гиперплоскости будут одного класса объекты, с другой --- другого класса объекта. Тогда $c(x)$ можно переписать в следующем виде:\\n\\n\\\\[\\nc(x) = \\\\sgn(f(x)) = \\\\sgn(x^T w)\\n\\\\]\\n\\nВведём понятие margin (отступ):\\n\\n\\\\[\\nM_i = y_i f(x_i) = y_i x_i^T w\\n\\\\]\\n\\nЭто некоторый аналог ориентированного расстояния, причём если $M_i \\\\leqslant 0$, значит объект классифицирован неправильно. Тогда логично предложить следующую функцию потерь:\\n\\n\\\\[\\n\\\\text{Loss} = \\\\sum_{\\\\text{by objects}} [M_i \\\\leqslant 0]\\n\\\\]\\n\\nНо у такой loss function будут проблемы, так как это не гладкая функция. Это главная причина почему мы\\nне будем использовать такой loss, по крайней мере в наших текущих задачах. Есть ещё один менее очевидный\\nминус: такая метрика ничего нам не говорит об уверенности классификатора. Представьте объекты как точки\\nв пространстве признаков, есть гиперплоскость классификатора, и было бы разумно полагать, что объекты\\nна границе, где перемешиваются два класса, будут с меньшей уверенностью разделены классификатором, чем\\nлежащие далеко \"в толще\"класса, которые с большей точностью принадлежат своему классу.\\n\\nЧто можно сделать с имеющейся функцией потерь --- приблизить её к гладкой функции. Предлагается использовать логистическую регрессию.\\n\\n\\\\[\\np_+ = P(y = 1|x) \\\\in [0, 1]\\n\\\\]\\n\\nРегрессионная модель живет в пространстве $\\\\R$, а вероятность живёт исключительно в промежутке [0,1]. Как с этим быть?\\nПрименить функцию, которая переводит R в промежуток [0,1] и таким образом моделлирует вероятность.\\nИспользуем некий трюк и составим величину, которая уже будет куда ближе к R:\\n$\\\\frac{p_+}{1 - p_+} \\\\in [0, +\\\\infty)$\\n\\nОсталось отразить промежуток $[0, +\\\\infty]$ в $\\\\R$, с чем хорошо справляется функция логарифма:\\n$\\\\log \\\\frac{p_+}{1 - p_+} \\\\in \\\\R$\\nТаким образом мы объединили мир классификации и мир регрессии. Теперь запишем предсказание через\\nвектор признаков и вектор весов, а также выразим вероятность объекта иметь класс 1:\\n\\\\[\\n\\\\frac{p_+}{1 - p_+} = \\\\exp(x^T w)\\n\\\\]\\n\\\\[\\np_+ = \\\\frac{1}{1 + \\\\exp(-x^T w)} = \\\\sigma(x^T w)\\n\\\\]\\nПолучилось, что вероятность объекта иметь 1 класс равна сигмоиде от привычного выражения для линейной\\nрегрессии.', 'title': 'Logistic regression. Equivalence of MLE approach and logistic loss minimization.'}, page_content='Logistic regression. Equivalence of MLE approach and logistic loss minimization.'),\n",
       " Document(id='a42cd765-8fac-4c09-be0d-6d4b1a9b4cce', metadata={'text': '\\\\textbf{Постановка задачи}\\n\\nПусть задан датасет \\\\( \\\\mathcal{L} = \\\\{x_i, y_i\\\\}_{i = 1}^N\\\\),\\nгде \\\\(x_i \\\\in \\\\R^n, y_i \\\\in \\\\R\\\\).\\nНаша модель линейная, то есть предсказание выглядит следующим образом:\\n\\n\\\\[\\n\\\\widehat{y} = w_0 + \\\\sum_{k = 1}^p x_k \\\\cdot w_k = x^T w\\n\\\\]\\n\\nЧтобы отдельно не записывать свободный член, добавим в $x$ признак, тождественно равный единице. Тогда соответствующий коэффициент в $w$ будет отвечать за свободный член:\\n\\n\\\\[\\n\\\\begin{pmatrix}\\n1 & x_1 & \\\\ldots & x_p\\n\\\\end{pmatrix}\\n\\\\begin{pmatrix}\\nw_0 \\\\\\\\\\nw_1 \\\\\\\\\\n\\\\ldots \\\\\\\\\\nw_p\\n\\\\end{pmatrix}\\n= w_0 + \\\\sum_{k = 1}^p x_k \\\\cdot w_k\\n\\\\]\\n\\nЗадача оптимизации, которую мы решаем -- это минимизация какого-то функционала. Например, среднеквадратичной ошибки (такой подход называется методом наименьших квадратов):\\n\\n\\\\[\\n\\\\widehat{w} = \\\\arg \\\\min_w \\\\|Y - \\\\widehat{Y}\\\\|_2^2 = \\n\\\\arg \\\\min_w \\\\|Y - Xw\\\\|_2^2\\n\\\\]\\n\\nВ случае минимизации среднеквадратичной ошибки существует аналитическое решение:\\n\\n\\\\begin{multline*}\\n\\\\|Y - Xw\\\\|_2^2 = \\\\langle Y - Xw, Y - Xw \\\\rangle = \\nY^T Y - (Xw)^T Y - Y^T (Xw) + (Xw)^T Xw = \\\\\\\\\\n= Y^T Y - w^T X^T Y - Y^T X w + w^T X^T X w\\n\\\\end{multline*}\\n\\n\\\\[\\n\\\\nabla_w \\\\|Y - Xw\\\\|_2^2 = 0 - X^T Y - X^T Y + \\n\\\\left( X^T X + X^T X \\\\right) w\\n\\\\]\\n\\nПриравнивая \\\\(\\\\nabla_w \\\\|Y - Xw\\\\|_2^2\\\\) к нулю, получаем:\\n\\n\\\\[\\n\\\\widehat{w} = (X^T X)^{-1} X^T Y\\n\\\\]\\n\\n\\\\begin{note}\\nАналитическое решение существует только для 2-нормы. Для остальных норм решение ищется только градиентными методами.\\n\\\\end{note}\\n\\n\\\\begin{theorem}[Гаусса-Маркова]\\nПусть целевые значения выражаются в следующем виде:\\n\\n\\\\(Y = Xw + \\\\varepsilon\\\\), где \\n\\\\(\\\\varepsilon = (\\\\varepsilon_1, \\\\ldots, \\\\varepsilon_N)\\\\) -- случайный вектор, при этом:\\n\\n\\\\begin{enumerate}\\n    \\\\item \\\\(\\\\mathbb{E} \\\\varepsilon_i = 0\\\\ \\\\forall i\\\\)\\n    \\\\item \\\\(\\\\mathbb{D} \\\\varepsilon_i = \\\\sigma^2 < \\\\infty\\\\ \\\\forall i\\\\)\\n    \\\\item \\\\(\\\\text{cov}(\\\\varepsilon_i, \\\\varepsilon_j) = 0\\\\ \\\\forall i \\\\neq j\\\\)\\n\\\\end{enumerate}\\n\\nТогда решение задачи наименьших квадратов \\n$\\\\widehat{w} = (X^T X)^{-1} X^T Y$ является оптимальным среди несмещённых.\\n\\nДругими словами, $\\\\widehat{w}$ является несмещённой (\\\\(\\\\mathbb{E} \\\\widehat{w} = w\\\\)) и оптимальной (то есть имеет наименьшую дисперсию среди всех несмещённых).\\n\\n\\\\textbf{Основные функции потерь в регрессии}\\n\\n\\\\[\\n\\\\text{MSE}(y, \\\\widehat{y}) = \\n\\\\frac{1}{N} \\\\|y - \\\\widehat{y}\\\\|_2^2 = \\n\\\\frac{1}{N} \\\\sum_i (y_i - \\\\widehat{y_i})^2\\n\\\\]\\n\\n\\\\begin{itemize}\\n    \\\\item Применима теорема Гаусса-Маркова\\n    \\\\item Дифференцируема\\n    \\\\item Чувствительна к шуму\\n\\\\end{itemize}\\n\\n\\\\[\\n\\\\text{MAE}(y, \\\\widehat{y}) = \\n\\\\frac{1}{N} \\\\|y - \\\\widehat{y}\\\\|_1 = \\n\\\\frac{1}{N} \\\\sum_i |y_i - \\\\widehat{y_i}|\\n\\\\]\\n\\n\\\\begin{itemize}\\n    \\\\item Не дифференцируема (можно доопределить производную в нуле нулём)\\n    \\\\item Более устойчива к шуму\\n\\\\end{itemize}\\n\\n\\\\end{theorem}\\n', 'title': 'Linear regression. Problem statement for the MSE loss function case. Analytical solution. Gauss-Markov theorem. Gradient approach in linear regression.'}, page_content='Linear regression. Problem statement for the MSE loss function case. Analytical solution. Gauss-Markov theorem. Gradient approach in linear regression.'),\n",
       " Document(id='a5d17162-3a33-48c2-9988-fc5a82175e4b', metadata={'text': 'Функция правдоподобия это ни что иное как условная вероятность выборки, при условии что\\nпараметрические семейство, которое описывает эту выборку обладает ровно таким параметром.\\n$$L(\\\\theta | X, Y ) = P(X, Y |\\\\theta)$$\\nОт правдоподобия мы хотим только одну вещь - максимизировать. Хотим наиболее правдоподобные параметры\\nпри условии нашей выборки.\\n$$L(\\\\theta | X, Y ) \\\\rightarrow \\\\underset{\\\\theta}{\\\\max}$$\\nТак как матрица признаков имеет незаивисимые объекты i.i.d, мы можем расписать условную вероятность\\nкак произведение условной вероятности по каждому объекту.\\n$$L(\\\\theta|X, Y ) = P(X, Y |\\\\theta) = \\\\prod\\\\limits_i P(x_i, y_i |\\\\theta)$$\\nArgmax функции совпадает с argmax любого монотонного преобразования над функцией. Тут можно использовать логарифм, который из произведения делает сумму, логарифм - монотонное преобразование, поэтому\\nмы можем заменить произведение на сумму логарифмов условной вероятности и его уже максимизировать:\\n$$log L(\\\\theta|X, Y ) = P(X, Y |\\\\theta) = \\\\sum\\\\limits_i log P(x\\n_i, y_i |\\\\theta)  \\\\rightarrow \\\\underset{\\\\theta}{\\\\max}$$\\n\\\\\\\\\\n\\\\begin{note}\\nФУНКЦИЯ ПРАВДОПОДОБИЯ - ЭТО НЕ РАСПРЕДЕЛЕНИЕ НАД ПАРАМЕТРАМИ $\\\\theta$\\n\\n\\\\end{note}\\n\\n\\\\begin{note}\\n\\\\\\n\\\\\\\\\\n\\nБольшинство моделей работает по принципу максимального правдоподобия, линейная регрессия и классфикация работают именно по нему.\\n\\nВ задаче линейной регресси мы ходим минимизировать MSE для получения оптимального вектора весов. Задача минимизации MSE эквивалентна методу максимального правдоподобия при определенных условиях по теореме Гаусса-Маркова.\\n\\\\\\\\\\nВ задаче классификации мы напрямую используем MLE для выбора параметров\\n\\\\end{note}\\n\\n', 'title': 'Maximum likelihood estimation, how is it related to regression and classification'}, page_content='Maximum likelihood estimation, how is it related to regression and classification'),\n",
       " Document(id='04c86d65-6bc5-4301-8dab-08b2a38d306b', metadata={'text': '\\\\textbf{Random Subspace Method (RSM):} случайно выбираем некоторые наборы признаков, обучаем модель только на них и усредняем результаты. Из-за того, что наборы признаков разные, ошибки не очень похожи друг на друга, а значит мы приближаемся к теоретическому результату из прошлого билета\\n\\n\\\\textbf{Random Forest:} объединим bagging и RSM на деревьях, чтобы ошибки стали еще менее похожими\\n\\nПлюсы random forest: нелинейная разделяющая поверхность, сложно переобучить (переобучения всех деревьев усредняются, проблемы могут быть только если возьмем огромное количество деревьев и наборы признаков будут повторяться), не ломается при наличии скоррелированных признаков, деревья хорошо работают с пропусками (если нет признака, который нужен для этого листа, просто считаем значения в каждой из веток и усредняем)\\n\\n\\\\[ \\\\hat{y} = \\\\frac{|L|}{|Q|} \\\\hat{y_L} + \\\\frac{|R|}{|Q|} \\\\hat{y_R}\\\\]\\n\\nТак же random forest позволяет использовать обучающую выборку для валидации: так как мы обучаем каждое дерево на бутстрапной выборке, есть объекты, которые каждая из моделей не видела. Поэтому можно для каждого объекта взять только те модели, которые его не видели и усреднить предсказания по ним. Получим оценку сверху на ошибку (так как уменьшили ансамбль, следовательно ошибка выросла).\\n\\n\\\\[ OOB = \\\\sum_{i=1}^m L\\\\left(y_i, \\\\frac 1 {\\\\sum_{n=1}^N I[x_i \\\\not\\\\in X_n]} \\\\sum_{n=1}^N I[x_i \\\\not\\\\in X_n] b_n(x_i)\\\\right) \\\\quad \\\\text{(out-of-bag error)} \\\\]\\n\\n\\\\begin{lemmanote}\\n    Если данные упорядочены во времени надо быть очень осторожными с OOB, потому что важно смотреть распределение <<новое при условии старого>>, а не наоборот (иначе модель обучается чему-то не тому)\\n\\\\end{lemmanote}\\n\\\\textbf{Модификации:}\\n\\\\begin{enumerate}\\n    \\\\item Extremely Randomized Trees: выбираем разделения в листах более рандомно (в экстремальном случае: деревья даже не зависят от ответов обучающей выборки)\\n\\n    \\\\item Isolation forest (метод поиска аномалий): не предсказываем что-то, а пытаемся отделить аномалии, так как их проще отделить деревом чем остальные точки (этот метод не универсальный, работает не на всех задачах. Пример: точки на плоскости, <<свернули в рулон>> и добавили аномалии между слоями. Метод будет работать плохо)\\n\\\\end{enumerate}', 'title': 'Random Forest, Random subspace method.'}, page_content='Random Forest, Random subspace method.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retriever test:\n",
    "query = 'Что такое линейная регрессия? Какие метрики используются в задачах регрессии?'\n",
    "\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\", \n",
    "    search_kwargs={\"k\": 5}\n",
    ")\n",
    "\n",
    "retrieved = retriever.invoke(query)\n",
    "retrieved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Regularization in linear models: L1 и L2, their properties. Probabilistic interpretation.',\n",
       " 'Logistic regression. Equivalence of MLE approach and logistic loss minimization.',\n",
       " 'Linear regression. Problem statement for the MSE loss function case. Analytical solution. Gauss-Markov theorem. Gradient approach in linear regression.',\n",
       " 'Maximum likelihood estimation, how is it related to regression and classification',\n",
       " 'Random Forest, Random subspace method.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[elem.metadata[\"title\"] for elem in retrieved]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add llm and pipeline via langchain graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain.chains\n",
    "import langchain.prompts\n",
    "from yandex_chain import YandexLLM, YandexGPTModel\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "model = YandexLLM(\n",
    "    folder_id=folder_id,\n",
    "    api_key=api_key,\n",
    "    model=YandexGPTModel.Pro\n",
    ")\n",
    "\n",
    "prompt = langchain.prompts.PromptTemplate(\n",
    "    template = '''\n",
    "        Посмотри на предложенные фрагменты конспекта и ответь на вопрос. Старайся использовать информацию из предложенного текста. Отвечай кратко, без дополнительных пояснений.\n",
    "        Контекст:\n",
    "        #####\n",
    "        {context}\n",
    "        #####\n",
    "        Вопрос:\n",
    "        #####\n",
    "        {question}''',\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = retriever.invoke(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.metadata[\"text\"] for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = model.invoke(messages)\n",
    "    return {\"answer\": response}\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke({\"question\": \"Что такое линейная регрессия? Какие метрики используются в задачах регрессии?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Линейная регрессия — это модель, использующая линейную функцию для предсказания значений на основе вектора признаков.\n",
      "\n",
      "В задачах регрессии используются следующие метрики:\n",
      "* MSE (среднеквадратичная ошибка);\n",
      "* MAE (средняя абсолютная ошибка).\n"
     ]
    }
   ],
   "source": [
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
